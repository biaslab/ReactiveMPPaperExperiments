{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using DrWatson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@quickactivate :ReactiveMPPaperExperiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CairoMakie # Plots related stuff\n",
    "using Turing, Distributions, LinearAlgebra, Random # Bayesian Inference packages\n",
    "using BenchmarkTools, DataFrames, Query # Analysis tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we want to compare results and performance of ReactiveMP.jl with another probabilistic programming library which is called Turing.jl. Turing is a general probabilistic programming toolbox and does not use message passing for inference procedure, but sampling. Message passing has an advantage over sampling approach for conjugate models (which our linear gaussian state space model is) because it may fallback to analytically tractable update rules, where sampling cannot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Turing.@model LinearGaussianSSM(y, A, B, P, Q) = begin\n",
    "    n = length(y)\n",
    "\n",
    "    # State sequence.\n",
    "    x = Vector(undef, n)\n",
    "\n",
    "    d = first(size(A))\n",
    "    pm = zeros(d)\n",
    "    pc = Matrix(Diagonal(100.0 * ones(d)))\n",
    "\n",
    "    # Observe each point of the input.\n",
    "    x[1] ~ MvNormal(pm, pc)\n",
    "    y[1] ~ MvNormal(B * x[1], Q)\n",
    "\n",
    "    for t in 2:n\n",
    "        x[t] ~ MvNormal(A * x[t - 1], P)\n",
    "        y[t] ~ MvNormal(B * x[t], Q)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = let \n",
    "    seed = 42\n",
    "    n    = 50\n",
    "    d    = 2\n",
    "    θ    = π / 20\n",
    "\n",
    "    A = rotation_matrix(θ)\n",
    "    B = diagonal_matrix([ 1.3, 0.7 ])\n",
    "    P = diagonal_matrix([ 1.0, 1.0 ])\n",
    "    Q = diagonal_matrix([ 1.0, 1.0 ]);\n",
    "\n",
    "    @strdict seed n d θ A B P Q\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Turing's builtin HMC sampler to perform inference on this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inference_turing (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function inference_turing(observations, params; nsamples = 250, seed = 42)\n",
    "    @unpack A, B, P, Q = params\n",
    "    rng = MersenneTwister(seed)\n",
    "    return Turing.sample(rng, \n",
    "        LinearGaussianSSM(observations, A, B, P, Q), Turing.HMC(0.1, 10), \n",
    "        nsamples\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:08\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "x_turing, y_turing = generate_data(LGSSMModel(), params);\n",
    "x_turing_estimated = inference_turing(y_turing, params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: 194.7855967730789\n"
     ]
    }
   ],
   "source": [
    "println(\"Average MSE: $(average_mse(x_turing, x_turing_estimated, :x, MvNormal))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let\n",
    "    reshape_data        = (data) -> transpose(reduce(hcat, data))\n",
    "    reshape_turing_data = (data) -> transpose(reshape(data, (2, Int(length(data) / 2))))\n",
    "\n",
    "    ylimit = (-15, 20)\n",
    "    c = Makie.wong_colors()\n",
    "    \n",
    "    n_turing = length(y_turing)\n",
    "    samples  = get(x_turing_estimated, :x)\n",
    "    \n",
    "    x_inferred_means = reshape_turing_data([ mean(samples.x[i].data) for i in 1:2n_turing ]) |> collect |> eachrow |> collect\n",
    "    x_inferred_stds = reshape_turing_data([ std(samples.x[i].data) for i in 1:2n_turing ]) |> collect |> eachrow |> collect\n",
    "    \n",
    "\n",
    "    range = 1:n_turing\n",
    "\n",
    "    fig = Figure(resolution = (550, 350))\n",
    "    ax  = Makie.Axis(fig[1, 1], xlabel = \"Time step k\", ylabel = \"Latent states\")\n",
    "\n",
    "    ylims!(ax, ylimit)\n",
    "\n",
    "    # Real dim1\n",
    "\n",
    "    lines!(ax, range, x_turing |> edim(1), color = :red3, linewidth = 1.75, label = \"x[:, 1]\")\n",
    "    scatter!(ax, range, y_turing |> edim(1), color = (:red3, 0.35), markersize = 10, marker = :cross)\n",
    "\n",
    "    # Estimated dim1\n",
    "\n",
    "    lines!(ax, range, x_inferred_means |> edim(1), color = c[3], label = \"estimated[:, 1]\")\n",
    "    band!(ax, range, (x_inferred_means |> edim(1)) .+ (x_inferred_stds |> edim(1)), (x_inferred_means |> edim(1)) .- (x_inferred_stds |> edim(1)), color = (c[3], 0.65))\n",
    "\n",
    "    # Real dim2\n",
    "\n",
    "    lines!(ax, range, x_turing |> edim(2), color = :purple, linewidth = 1.75, linestyle = :dash, label = \"x[:, 2]\")\n",
    "    scatter!(ax, range, y_turing |> edim(2), color = (:purple, 0.35), markersize = 6, marker = :circle)\n",
    "\n",
    "    # Estimated dim2\n",
    "\n",
    "    lines!(ax, range, x_inferred_means |> edim(2), color = c[1], label = \"estimated[:, 2]\")\n",
    "    band!(ax, range, (x_inferred_means |> edim(2)) .+ (x_inferred_stds |> edim(2)), (x_inferred_means |> edim(2)) .- (x_inferred_stds |> edim(2)), color = (c[1], 0.65))\n",
    "\n",
    "    axislegend(ax, position = :lt, labelsize = 16)\n",
    "\n",
    "    @saveplot fig \"lgssm_turing_inference\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function run_turing_benchmark(params)\n",
    "    @unpack n, seed, d, nsamples = params\n",
    "\n",
    "    rng = MersenneTwister(seed)\n",
    "\n",
    "    A = random_rotation_matrix(rng, d)\n",
    "    B = random_rotation_matrix(rng, d)\n",
    "    P = Matrix(Diagonal(ones(d)))\n",
    "    Q = Matrix(Diagonal(ones(d)))\n",
    "\n",
    "    data_params = @strdict n d seed A B P Q\n",
    "    \n",
    "    x, y = generate_data(LGSSMModel(), data_params)\n",
    "\n",
    "    x_estimated = inference_turing(y, data_params, nsamples = nsamples);\n",
    "    benchmark   = @benchmark inference_turing(\n",
    "        $y, $data_params, nsamples = $nsamples\n",
    "    )\n",
    "    amse = average_mse(x, x_estimated, :x, MvNormal)\n",
    "\n",
    "    output = @strdict n seed d amse nsamples x_estimated benchmark\n",
    "\n",
    "    return output\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create a list of parameters we want to run our benchmarks with\n",
    "benchmark_allparams_turing = dict_list(Dict(\n",
    "    \"n\"        => [ 50, 100, 250 ], # 500, 1000\n",
    "    \"seed\"     => 42,\n",
    "    \"d\"        => [ 2, 3, 4 ],\n",
    "    \"nsamples\" => [ 250, 500 ]\n",
    "));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First run maybe slow, you may track the progress in the terminal\n",
    "# Subsequent runs will not create new benchmarks \n",
    "# but will reload it from data folder\n",
    "turing_benchmarks = map(benchmark_allparams_turing) do params\n",
    "    path = datadir(\"benchmark\", \"lgssm\", \"turing\")\n",
    "    result, _ = produce_or_load(path, params; tag = false) do p\n",
    "        run_turing_benchmark(p)\n",
    "    end\n",
    "    return result\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compare `Turing.jl` performance results against smoothing algorithm performed in `ReactiveMP.jl`. We can see that `ReactiveMP.jl` outperforms `Turing.jl` significantly. It is worth noting that this model contains many conjugate prior and likelihood pairings that lead to analytically computable Bayesian posteriors. For these types of models, ReactiveMP.jl takes advantage of the conjugate pairings and beats general-purpose probabilistic programming packages like Turing.jl easily in terms of computational load, speed, memory and accuracy. On the other hand, Turing.jl is currently still capable of running inference for a broader set of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_nsamples = 500\n",
    "target_seed = 42\n",
    "target_d = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Scanning folder /Users/bvdmitri/.julia/dev/ReactiveMPPaperExperiments/data/benchmark/lgssm/turing for result files.\n",
      "└ @ DrWatson /Users/bvdmitri/.julia/packages/DrWatson/OgRKj/src/result_collection.jl:107\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>3 rows × 4 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>n</th><th>min</th><th>mean</th><th>amse</th></tr><tr><th></th><th title=\"Union{Missing, Int64}\">Int64?</th><th title=\"Union{Missing, String}\">String?</th><th title=\"Union{Missing, String}\">String?</th><th title=\"Union{Missing, Float64}\">Float64?</th></tr></thead><tbody><tr><th>1</th><td>50</td><td>26.17s</td><td>26.17s</td><td>159.683</td></tr><tr><th>2</th><td>100</td><td>98.451s</td><td>98.451s</td><td>320.009</td></tr><tr><th>3</th><td>250</td><td>587.993s</td><td>587.993s</td><td>881.41</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& n & min & mean & amse\\\\\n",
       "\t\\hline\n",
       "\t& Int64? & String? & String? & Float64?\\\\\n",
       "\t\\hline\n",
       "\t1 & 50 & 26.17s & 26.17s & 159.683 \\\\\n",
       "\t2 & 100 & 98.451s & 98.451s & 320.009 \\\\\n",
       "\t3 & 250 & 587.993s & 587.993s & 881.41 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3×4 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m n      \u001b[0m\u001b[1m min      \u001b[0m\u001b[1m mean     \u001b[0m\u001b[1m amse     \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64? \u001b[0m\u001b[90m String?  \u001b[0m\u001b[90m String?  \u001b[0m\u001b[90m Float64? \u001b[0m\n",
       "─────┼──────────────────────────────────────\n",
       "   1 │     50  26.17s    26.17s     159.683\n",
       "   2 │    100  98.451s   98.451s    320.009\n",
       "   3 │    250  587.993s  587.993s   881.41"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let\n",
    "    path_turing = datadir(\"benchmark\", \"lgssm\", \"turing\")\n",
    "\n",
    "    white_list   = [ \"n\", \"seed\", \"d\", \"nsamples\", \"amse\" ]\n",
    "    special_list = [\n",
    "        :min => (data) -> string(round(minimum(data[\"benchmark\"]).time / 1_000_000_000, digits = 3), \"s\"),\n",
    "        :mean => (data) -> string(round(mean(data[\"benchmark\"]).time / 1_000_000_000, digits = 3), \"s\"),\n",
    "    ]\n",
    "\n",
    "    df_turing    = collect_results(path_turing, white_list = white_list, special_list = special_list, verbose = false)\n",
    "\n",
    "    query_turing = @from row in df_turing begin\n",
    "        @where row.seed == target_seed && row.d == target_d && row.nsamples == target_nsamples\n",
    "        @orderby ascending(row.n)\n",
    "        @select { row.n, row.min, row.mean, row.amse }\n",
    "    end\n",
    "\n",
    "    DataFrame(query_turing)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
